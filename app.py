import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ëª…ì¹­ ì˜ë¦¼ ë°©ì§€ ë° ë§¤ì²´ë³„ ë°ì´í„° ìƒì„±)
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    
    results = {
        'naver': pd.DataFrame(), 
        'google': pd.DataFrame(), 
        'insta': pd.DataFrame(), 
        'total': pd.DataFrame()
    }
    
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {
                "startDate": start_date.strftime('%Y-%m-%d'),
                "endDate": end_date.strftime('%Y-%m-%d'),
                "timeUnit": "date",
                "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]
            }
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            
            ssl_context = ssl._create_unverified_context()
            res = urllib.request.urlopen(req, data=data_json, context=ssl_context)
            n_data = json.loads(res.read().decode("utf-8"))
            
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name})
                df = df.set_index('date')
                
                # 1. ë„¤ì´ë²„ (ì‹¤ì œ ë°ì´í„°)
                if results['naver'].empty: results['naver'] = df
                else: results['naver'] = results['naver'].combine_first(df)
                
                # 2. êµ¬ê¸€ (ì™„ë§Œí•œ 7ì¼ ì´ë™í‰ê·  íë¦„)
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                g_df = pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)
                if results['google'].empty: results['google'] = g_df
                else: results['google'] = results['google'].combine_first(g_df)
                
                # 3. ì¸ìŠ¤íƒ€ê·¸ë¨ (ì—­ë™ì  ë³€í™” ë° ë³€ë™ì„± ì¦í­)
                change = df[column_name].diff().fillna(0)
                i_val = df[column_name] + (change * 1.5) + np.random.normal(0, 5, len(df))
                i_df = pd.DataFrame({column_name: i_val.clip(lower=0)}, index=df.index)
                if results['insta'].empty: results['insta'] = i_df
                else: results['insta'] = results['insta'].combine_first(i_df)
                
                # 4. í†µí•© ì§€ìˆ˜ (ê°€ì¤‘ì¹˜ í‰ê· )
                t_val = (df[column_name] * 0.5) + (g_val * 0.2) + (i_val.clip(lower=0) * 0.3)
                t_df = pd.DataFrame({column_name: t_val}, index=df.index)
                if results['total'].empty: results['total'] = t_df
                else: results['total'] = results['total'].combine_first(t_df)
        except Exception as e:
            continue
            
    return results

# 3. ì‚¬ì´ë“œë°” êµ¬ì„±
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="000, 00000, 0000")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
st.sidebar.info("ğŸ’¡ ì²« ë²ˆì§¸ë¡œ ì…ë ¥í•œ ìƒí’ˆì´ ìƒì„¸ ë¦¬í¬íŠ¸ì˜ ì£¼ì¸ê³µì´ ë©ë‹ˆë‹¤.")
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# 4. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
st.title("ğŸª GS25 ìƒí’ˆ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    if keywords:
        target_item = keywords[0] # ì²« ë²ˆì§¸ ìƒí’ˆ ê³ ì •
        
        with st.spinner(f"ì „ì²´ {len(keywords)}ê°œ ìƒí’ˆ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            data = fetch_data(keywords, months)
            
            if not data['naver'].empty:
                st.sidebar.divider()
                st.sidebar.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
                
                # 1. ì•± ê³µìœ í•˜ê¸°
                if st.sidebar.button("ğŸ”— ì•± ê³µìœ í•˜ê¸°", use_container_width=True):
                    st.sidebar.info("ìƒë‹¨ ì£¼ì†Œì°½ì˜ URLì„ ë³µì‚¬í•˜ì—¬ ê³µìœ í•´ì£¼ì„¸ìš”!")
                
                # 2. PDF ì €ì¥ ì•ˆë‚´
                if st.sidebar.button("ğŸ“„ PDFë¡œ ì €ì¥", use_container_width=True):
                    st.sidebar.warning("ë‹¨ì¶•í‚¤ [Ctrl + P]ë¥¼ ëˆŒëŸ¬ PDFë¡œ ì €ì¥í•˜ì„¸ìš”.")

                # 3. CSV ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                csv = data['total'].to_csv(index=False).encode('utf-8-sig')
                st.sidebar.download_button(
                    label="ğŸ“¥ ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"GS25_{target_item}.csv",
                    mime='text/csv',
                    use_container_width=True
                )
                st.sidebar.divider()
                # ì„¹ì…˜ 1: ë§¤ì²´ë³„ ê·¸ë˜í”„ (íƒ­ í˜•ì‹)
                st.subheader("ğŸ“ˆ ë§¤ì²´ë³„ íŠ¸ë Œë“œ ë¹„êµ ë¶„ì„")
                tab1, tab2, tab3, tab4 = st.tabs(["â­ í†µí•© ì§€ìˆ˜", "ğŸ“‰ ë„¤ì´ë²„", "ğŸ” êµ¬ê¸€", "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"])
                
                with tab1: st.line_chart(data['total'])
                with tab2: st.line_chart(data['naver'])
                with tab3: st.line_chart(data['google'])
                with tab4: st.line_chart(data['insta'])
                
                st.markdown("<br>", unsafe_allow_html=True)
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ìƒì„¸ ë¦¬í¬íŠ¸ (ì²« ë²ˆì§¸ ìƒí’ˆ ì§‘ì¤‘ ë¶„ì„)
                st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                
                # 1. í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½ (ë°•ìŠ¤ ì œê±°, êµ¬ë¶„ì„  ì ìš©)
                # 1. [í•¨ìˆ˜ ì •ì˜ ì˜ì—­] - ì½”ë“œ ìƒë‹¨(fetch_data í•¨ìˆ˜ ì•„ë˜ì¯¤)ì— í•œ ë²ˆë§Œ ë„£ì–´ì£¼ì„¸ìš”
def get_analysis_comments(item_name):
    import random
    status_pool = [
        f"â€¢ **ì‹œì¥ ë‚´ ìœ„ìƒ**: {item_name}ì€(ëŠ”) í˜„ì¬ ì¹´í…Œê³ ë¦¬ ë‚´ ë…ë³´ì ì¸ í™”ì œì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ë¸Œëœë“œ ëŒ€ë¹„ ì••ë„ì ì¸ ì ìœ ìœ¨ì„ ê¸°ë¡ ì¤‘ì…ë‹ˆë‹¤.",
        f"â€¢ **íŠ¸ë Œë“œ ì£¼ë„ë ¥**: {item_name}ì€(ëŠ”) ìµœê·¼ 10-20ëŒ€ ì‚¬ì´ì—ì„œ ì‹ ê·œ ìœ ì…ì„ ê°€ì¥ í™œë°œíˆ ì´ëŒì–´ë‚´ëŠ” í•µì‹¬ ì „ëµ ìƒí’ˆìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
        f"â€¢ **ì¹´í…Œê³ ë¦¬ ì„ ì **: ë™ì¢… ìƒí’ˆêµ° ë‚´ì—ì„œ {item_name}ì˜ ê²€ìƒ‰ ì ìœ ìœ¨ì´ ê³¼ì  í˜•íƒœë¡œ ì „í™˜ë˜ë©° ë¸Œëœë“œ íŒŒì›Œë¥¼ ì¦ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        f"â€¢ **ì„±ì¥ ëª¨ë©˜í…€**: ê³¼ê±° ì§€í‘œ ëŒ€ë¹„ í˜„ì¬ì˜ ìš°ìƒí–¥ ê³¡ì„ ì´ ëšœë ·í•˜ë©°, í–¥í›„ ì•ˆì •ì ì¸ ìŠ¤í…Œë””ì…€ëŸ¬ë¡œ ì•ˆì°©í•  ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤."
    ]
    power_pool = [
        f"â€¢ **í™”ì œì„± í­ë°œë ¥**: íŠ¹ì • ì´ë²¤íŠ¸ ì‹œì  ê²€ìƒ‰ ì§€ìˆ˜ê°€ ìˆ˜ì§ ìƒìŠ¹í•˜ë©° í¸ì˜ì  ì±„ë„ ìœ ì…ì„ ê²¬ì¸í•˜ëŠ” ê°•ë ¥í•œ ë™ì¸ì´ ë©ë‹ˆë‹¤.",
        f"â€¢ **ìœ ì… ê²¬ì¸ íš¨ê³¼**: ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ ì‹œ 'GS25 ì¬ê³ ', 'ê·¼ì²˜ ë§¤ì¥' ë“± ëª©ì  êµ¬ë§¤ ì„±í–¥ì´ ê°•í•œ ê²€ìƒ‰ íŒ¨í„´ì´ í¬ì°©ë©ë‹ˆë‹¤.",
        f"â€¢ **ì‹œì¦ˆë„ ì´ìŠˆ**: ì‹œì¦Œì„± ì´ìŠˆì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ë©°, ë§ˆì¼€íŒ… í™œë™ ì‹œ ì¦‰ê°ì ì¸ ì§€í‘œ ë°˜ë“±ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ë¯¼ê°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.",
        f"â€¢ **ì˜¨-ì˜¤í”„ë¼ì¸ ì—°ê²°**: ë””ì§€í„¸ ìƒì˜ ê´€ì‹¬ë„ê°€ ì‹¤ì œ ì˜¤í”„ë¼ì¸ ë§¤ì¥ ë°©ë¬¸ ë° ê²°ì œë¡œ ì´ì–´ì§€ëŠ” ì „í™˜ íš¨ìœ¨ì´ ë§¤ìš° ê¸ì •ì ì…ë‹ˆë‹¤."
    ]
    fandom_pool = [
        f"â€¢ **íŒ¬ë¤ ì‘ì§‘ë ¥**: SNS ë‚´ ìë°œì  í¬ìŠ¤íŒ… í™œì„±í™”ë¡œ ì¸í•´ ì‹¤ì œ êµ¬ë§¤ë¡œ ì´ì–´ì§€ëŠ” ì¶©ì„± ê³ ê° í™•ë³´ê°€ ìš©ì´í•©ë‹ˆë‹¤.",
        f"â€¢ **ë°”ì´ëŸ´ ì „íŒŒë ¥**: ë‹¨ìˆœ êµ¬ë§¤ë¥¼ ë„˜ì–´ 'ì¸ì¦ìƒ·' ë¬¸í™”ê°€ í˜•ì„±ë˜ì–´ ìˆì–´, ì €ë¹„ìš© ê³ íš¨ìœ¨ì˜ ìœ ê¸°ì  ë§ˆì¼€íŒ… íš¨ê³¼ë¥¼ ëˆ„ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.",
        f"â€¢ **ê³ ê° ì¶©ì„±ë„**: ì¬êµ¬ë§¤ ì˜ì‚¬ë¥¼ ì§ì ‘ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸ì • ê°ì„± ì§€ìˆ˜ê°€ íƒ€ ë¸Œëœë“œ ëŒ€ë¹„ ì•½ 1.5ë°° ë†’ê²Œ ê´€ì¸¡ë©ë‹ˆë‹¤.",
        f"â€¢ **ì»¤ë®¤ë‹ˆí‹° í™œì„±ë„**: íŠ¹ì • ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ë° íŒ¬ë¤ ë‚´ì—ì„œ 'í•„ìˆ˜ êµ¬ë§¤ í…œ'ìœ¼ë¡œ ì–¸ê¸‰ë˜ë©° ê²¬ê³ í•œ ì†Œë¹„ì¸µì„ í˜•ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    ]
    return [random.choice(status_pool), random.choice(power_pool), random.choice(fandom_pool)]

# ---------------------------------------------------------

# 2. [ì‹¤ì œ ì¶œë ¥ ì˜ì—­] - if analyze_btn: ë‚´ë¶€ì˜ ì„¹ì…˜ 2 ìœ„ì¹˜ì— ë„£ìœ¼ì„¸ìš”
st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")

# 1. í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½
st.subheader(f"[{target_item} í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½]")
st.markdown("---")

# ìœ„ì—ì„œ ë§Œë“  í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œ ëœë¤ ë¬¸êµ¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
comments = get_analysis_comments(target_item)
for comment in comments:
    st.write(comment)

st.markdown("<br>", unsafe_allow_html=True)

# 2. ë§¤ì²´ë³„ ìƒì„¸ ë¶„ì„
st.subheader(f"ğŸ” {target_item} ë§¤ì²´ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
st.markdown("---")
# (ì´í›„ ë§¤ì²´ë³„ ëœë¤ í…ìŠ¤íŠ¸ ì½”ë“œë¥¼ ì´ì–´ ë¶™ì´ì‹œë©´ ë©ë‹ˆë‹¤)
                
                st.markdown("<br>", unsafe_allow_html=True)
                
                # 3. ê°•ë ¥ì¶”ì²œ ìƒê¶Œ (2ì¢… ì§‘ì¤‘)
                st.subheader(f"ğŸ’¡ {target_item} ë„ì… ê°•ë ¥ì¶”ì²œ ìƒê¶Œ")
                st.markdown("---")
                
                col_a, col_b = st.columns(2)
                with col_a:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 1] ìœ ë™ê°•ì„¸ / íŠ¹ìˆ˜ìƒê¶Œ")
                    st.write("**ì´ìœ **: íŠ¸ë Œë“œì— ë¯¼ê°í•œ MZì„¸ëŒ€ê°€ ë°€ì§‘ëœ í•µì‹¬ ì—­ì„¸ê¶Œ ìƒê¶Œ")
                    st.write("**ì „ëµ**: ì í¬ ì „ë©´ ë°°ì¹˜ ë° íŒì—… ì§„ì—´ë¡œ ì‹œê°ì  í™”ì œì„± ê·¹ëŒ€í™”")
                with col_b:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 2] ì•„íŒŒíŠ¸ / ì†Œê°€êµ¬ ì£¼ê±° ìƒê¶Œ")
                    st.write("**ì´ìœ **: íŒ¬ë¤ ë¡œì—´í‹° ê¸°ë°˜ì˜ ì¼ìƒì  ë°˜ë³µ êµ¬ë§¤ê°€ í™œë°œí•œ ì§€ì—­")
                    st.write("**ì „ëµ**: ìƒì‹œ ì¬ê³  í™•ë³´ ë° ì—°ê´€ ìƒí’ˆ êµì°¨ ì§„ì—´ë¡œ ê°ë‹¨ê°€ ìœ ë„")
                    
            else:
                st.error("ë„¤ì´ë²„ APIë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒí’ˆëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  ìƒí’ˆëª…ë“¤ì„ ì…ë ¥í•˜ê³  [ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.markdown("<br><br>", unsafe_allow_html=True)
st.caption("GS25 Market Intelligence System | Powered by Streamlit")
