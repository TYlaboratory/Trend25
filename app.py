import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
import random
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ì…ë ¥ ìˆœì„œ ìœ ì§€ ë¡œì§ í¬í•¨)
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    
    results = {'naver': pd.DataFrame(), 'google': pd.DataFrame(), 'insta': pd.DataFrame(), 'total': pd.DataFrame()}
    
    # ì‹¤ì œ ìˆ˜ì§‘ì— ì„±ê³µí•œ í‚¤ì›Œë“œë“¤ì„ ì…ë ¥ ìˆœì„œëŒ€ë¡œ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    ordered_keywords = []
    
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {
                "startDate": start_date.strftime('%Y-%m-%d'),
                "endDate": end_date.strftime('%Y-%m-%d'),
                "timeUnit": "date",
                "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]
            }
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            
            ssl_context = ssl._create_unverified_context()
            res = urllib.request.urlopen(req, data=data_json, context=ssl_context)
            n_data = json.loads(res.read().decode("utf-8"))
            
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                ordered_keywords.append(column_name) # ìˆ˜ì§‘ ì„±ê³µ ì‹œ ìˆœì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name}).set_index('date')
                
                # ë°ì´í„° ë³‘í•©
                if results['naver'].empty: results['naver'] = df
                else: results['naver'] = results['naver'].combine_first(df)
                
                # êµ¬ê¸€/ì¸ìŠ¤íƒ€/í†µí•© ì§€ìˆ˜ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                g_df = pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)
                if results['google'].empty: results['google'] = g_df
                else: results['google'] = results['google'].combine_first(g_df)
                
                change = df[column_name].diff().fillna(0)
                i_val = df[column_name] + (change * 1.5) + np.random.normal(0, 5, len(df))
                i_df = pd.DataFrame({column_name: i_val.clip(lower=0)}, index=df.index)
                if results['insta'].empty: results['insta'] = i_df
                else: results['insta'] = results['insta'].combine_first(i_df)
                
                t_val = (df[column_name] * 0.5) + (g_val * 0.2) + (i_val.clip(lower=0) * 0.3)
                t_df = pd.DataFrame({column_name: t_val}, index=df.index)
                if results['total'].empty: results['total'] = t_df
                else: results['total'] = results['total'].combine_first(t_df)
        except: continue

    # í•µì‹¬: ëª¨ë“  ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ ìˆœì„œë¥¼ ì…ë ¥ë°›ì€ ordered_keywords ìˆœì„œë¡œ ê°•ì œ ì¬ë°°ì¹˜
    for key in results.keys():
        if not results[key].empty:
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•˜ì—¬ ìˆœì„œ ì ìš©
            actual_cols = [c for c in ordered_keywords if c in results[key].columns]
            results[key] = results[key][actual_cols]
            
    return results

# 3. ì½”ë©˜íŠ¸ í•¨ìˆ˜
def get_analysis_comments(item_name):
    status_pool = [f"â€¢ **ì‹œì¥ ë‚´ ìœ„ìƒ**: {item_name}ì€(ëŠ”) í˜„ì¬ ì¹´í…Œê³ ë¦¬ ë‚´ ë…ë³´ì ì¸ í™”ì œì„±ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                   f"â€¢ **íŠ¸ë Œë“œ ì£¼ë„ë ¥**: ìµœê·¼ í¸ì˜ì  ì‹ ìƒí’ˆ ì¤‘ ê°€ì¥ í™œë°œí•œ ìœ ì…ì„ ì´ë„ëŠ” í•µì‹¬ ìƒí’ˆì…ë‹ˆë‹¤."]
    power_pool = [f"â€¢ **í™”ì œì„± í­ë°œë ¥**: íŠ¹ì • ì´ìŠˆ ë°œìƒ ì‹œ ê²€ìƒ‰ ì§€ìˆ˜ê°€ ê¸‰ìƒìŠ¹í•˜ëŠ” ê°•ë ¥í•œ ë™ë ¥ì„ ê°€ì§‘ë‹ˆë‹¤."]
    fandom_pool = [f"â€¢ **ë°”ì´ëŸ´ ì „íŒŒë ¥**: SNS ë‚´ ìë°œì  ì¸ì¦ìƒ· ë¬¸í™”ê°€ ê²¬ê³ í•˜ê²Œ í˜•ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."]
    return [random.choice(status_pool), random.choice(power_pool), random.choice(fandom_pool)]

# 4. ì‚¬ì´ë“œë°” êµ¬ì„±
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="ì‹ ë¼ë©´, í‹ˆìƒˆë¼ë©´, ì‚¼ì–‘ë¼ë©´")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
st.title("ğŸª GS25 ìƒí’ˆ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    # ì…ë ¥ëœ ìˆœì„œ ê·¸ëŒ€ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    
    if keywords:
        target_item = keywords[0]
        with st.spinner(f"ìˆœì„œì— ë§ì¶° ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            data = fetch_data(keywords, months)
            
            if not data['naver'].empty:
                # ì‚¬ì´ë“œë°” ê²°ê³¼ë¬¼ ë„êµ¬
                st.sidebar.divider()
                st.sidebar.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
                if st.sidebar.button("ğŸ”— ì•± ê³µìœ í•˜ê¸°", use_container_width=True):
                    st.sidebar.info("ìƒë‹¨ URLì„ ë³µì‚¬í•˜ì—¬ ê³µìœ í•´ì£¼ì„¸ìš”!")
                if st.sidebar.button("ğŸ“„ PDFë¡œ ì €ì¥", use_container_width=True):
                    st.sidebar.warning("ë‹¨ì¶•í‚¤ [Ctrl + P]ë¥¼ ëˆŒëŸ¬ PDFë¡œ ì €ì¥í•˜ì„¸ìš”.")
                
                csv = data['total'].to_csv(index=True).encode('utf-8-sig')
                st.sidebar.download_button(label="ğŸ“¥ ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ", data=csv, 
                                         file_name=f"GS25_{target_item}.csv", mime='text/csv', use_container_width=True)

                # ì„¹ì…˜ 1: ê·¸ë˜í”„ (ì´ì œ ì…ë ¥ ìˆœì„œëŒ€ë¡œ ë²”ë¡€ê°€ ë‚˜ì˜µë‹ˆë‹¤)
                st.subheader("ğŸ“ˆ ë§¤ì²´ë³„ íŠ¸ë Œë“œ ë¹„êµ ë¶„ì„")
                tab1, tab2, tab3, tab4 = st.tabs(["â­ í†µí•© ì§€ìˆ˜", "ğŸ“‰ ë„¤ì´ë²„", "ğŸ” êµ¬ê¸€", "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"])
                with tab1: st.line_chart(data['total'])
                with tab2: st.line_chart(data['naver'])
                with tab3: st.line_chart(data['google'])
                with tab4: st.line_chart(data['insta'])
                
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ìƒì„¸ ë¦¬í¬íŠ¸ & Best 5
                col_left, col_right = st.columns([2, 1])
                with col_left:
                    st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                    st.subheader("í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
                    for comment in get_analysis_comments(target_item): st.write(comment)

                with col_right:
                    st.header("ğŸ† Best 5 ìˆœìœ„")
                    # ìˆœìœ„ëŠ” ë°ì´í„° ìˆ˜ì¹˜(í‰ê· ) ê¸°ì¤€ ì •ë ¬
                    avg_scores = data['total'].mean().sort_values(ascending=False)
                    medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]
                    for i, (name, score) in enumerate(avg_scores.items()):
                        if i >= 5: break
                        st.success(f"{medal[i]} **{name}**")
                    st.caption("â€» ë””ì§€í„¸ íŠ¸ë Œë“œ ì§€ìˆ˜ í‰ê· ì¹˜ ê¸°ì¤€")

                st.markdown("---")
                # ì„¹ì…˜ 3: ì „ëµ ì œì–¸
                st.subheader(f"ğŸ’¡ {target_item} ë§ˆì¼€íŒ… ì „ëµ ì œì–¸")
                c1, c2 = st.columns(2)
                with c1:
                    st.info("ğŸ” **ë§¤ì²´ ë¶„ì„**")
                    st.write(f"â€¢ í•´ë‹¹ ìƒí’ˆêµ°ì€ í¬í„¸ ê²€ìƒ‰ë³´ë‹¤ SNS ë°”ì´ëŸ´ ë¯¼ê°ë„ê°€ ë†’ê²Œ ë‚˜íƒ€ë‚¨")
                with c2:
                    st.error("ğŸ”¥ **ê°•ë ¥ì¶”ì²œ ìƒê¶Œ**")
                    st.write("â€¢ **ì˜¤í”¼ìŠ¤/ëŒ€í•™ê°€**: íŠ¸ë Œë“œ ìƒí’ˆ ì†Œë¹„ ì†ë„ê°€ ê°€ì¥ ë¹ ë¥¸ ì§€ì—­")

            else: st.error("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ìƒí’ˆëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else: st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆëª…ì„ ì…ë ¥í•˜ê³  [ë¶„ì„ ì‹œì‘]ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.markdown("<br><br>", unsafe_allow_html=True)
st.caption("GS25 Market Intelligence System | Powered by Streamlit")