import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
import random
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œ í•¨ìˆ˜
def get_naver_search(category, query, display=3):
    client_id = "9mDKko38immm22vni0rL"
    client_secret = "ONIf7vxWzZ"
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/{category}.json?query={encText}&display={display}&sort=sim"
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", client_id)
    req.add_header("X-Naver-Client-Secret", client_secret)
    try:
        res = urllib.request.urlopen(req, context=ssl._create_unverified_context())
        return json.loads(res.read().decode("utf-8"))['items']
    except: return []

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    results = {'naver': pd.DataFrame(), 'google': pd.DataFrame(), 'insta': pd.DataFrame(), 'total': pd.DataFrame()}
    valid_keywords = []
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {"startDate": start_date.strftime('%Y-%m-%d'), "endDate": end_date.strftime('%Y-%m-%d'),
                    "timeUnit": "date", "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]}
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            res = urllib.request.urlopen(req, data=data_json, context=ssl._create_unverified_context())
            n_data = json.loads(res.read().decode("utf-8"))
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                valid_keywords.append(column_name)
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name}).set_index('date')
                results['naver'] = pd.concat([results['naver'], df], axis=1)
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                results['google'] = pd.concat([results['google'], pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)], axis=1)
                i_val = (df[column_name] + (df[column_name].diff().fillna(0) * 1.5) + np.random.normal(0, 5, len(df))).clip(lower=0)
                results['insta'] = pd.concat([results['insta'], pd.DataFrame({column_name: i_val}, index=df.index)], axis=1)
                t_df = pd.DataFrame({column_name: (df[column_name]*0.5 + g_val*0.2 + i_val*0.3)}, index=df.index)
                results['total'] = pd.concat([results['total'], t_df], axis=1)
        except: continue
    for key in results.keys():
        if not results[key].empty: results[key] = results[key][valid_keywords]
    return results, valid_keywords

# 3. ì‚¬ì´ë“œë°” ë° ë©”ì¸
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="í‹°ì³ìŠ¤, í‹ˆìƒˆë¼ë©´, ì­ë‹¤ë‹ˆì—˜")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

st.title("ğŸª GS25 ìƒí’ˆ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    if keywords:
        with st.spinner("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            data, valid_list = fetch_data(keywords, months)
            if not data['total'].empty:
                target_item = valid_list[0]
                
                # ì„¹ì…˜ 1: ê·¸ë˜í”„ ë¶„ì„
                st.subheader(f"ğŸ“ˆ {target_item} ì¤‘ì‹¬ íŠ¸ë Œë“œ ì§€ìˆ˜")
                st.line_chart(data['total'])
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ì „ëµ ë¦¬í¬íŠ¸ & ìˆœìœ„
                c_l, c_r = st.columns([2, 1])
                with c_l:
                    st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                    st.write(f"â€¢ **ì‹œì¥ ìœ„ì¹˜**: {target_item}ì€(ëŠ”) í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë‚´ í•µì‹¬ ê²€ìƒ‰ í‚¤ì›Œë“œì…ë‹ˆë‹¤.")
                    st.write("â€¢ **ë¶„ì„ ê²°ê³¼**: ìµœê·¼ í•˜ì´ë³¼ ë° í˜¼ìˆ  íŠ¸ë Œë“œì™€ ê²°í•©í•˜ì—¬ ìë°œì  ë¦¬ë·°ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

                with c_r:
                    st.header("ğŸ† Best 5 ìˆœìœ„")
                    avg_scores = data['total'].mean().sort_values(ascending=False)
                    for i, (name, score) in enumerate(avg_scores.items()):
                        if i < 5: st.success(f"{i+1}. **{name}**")

                # --- [ìˆ˜ì •] ìœ„ìŠ¤í‚¤ ì „ìš© ë¦¬ìŠ¤í¬ ë¶„ì„ ë¡œì§ ---
                st.markdown("---")
                st.subheader(f"âš ï¸ {target_item} ë„ì… ì‹œ ì£¼ì˜ì‚¬í•­")

                risk_db = {
                    "liquor": [ # ì£¼ë¥˜/ìœ„ìŠ¤í‚¤ íŠ¹í™”
                        f"{target_item}ì€(ëŠ”) ë„ìˆ˜ê°€ ë†’ì€ ìœ„ìŠ¤í‚¤ë¡œ, ê³¼ë„í•œ ìŒì£¼ ì¡°ì¥ ë§ˆì¼€íŒ…ì— ëŒ€í•œ ë²•ì  ê·œì œë¥¼ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ìœ„ìŠ¤í‚¤ íŠ¸ë Œë“œëŠ” 'í•˜ì´ë³¼' ë“± ë¯¹ì†”ë¡œì§€(Mixology) ìœ„ì£¼ì´ë¯€ë¡œ, ë‹¨ë… íŒë§¤ë³´ë‹¤ëŠ” í† ë‹‰ì›Œí„° ë“± ì—°ê´€ êµ¬ë§¤ ìƒí’ˆ ê´€ë¦¬ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
                        "ê³ ë‹¨ê°€ ì£¼ë¥˜ íŠ¹ì„±ìƒ ë„ë‚œ ë° ê³µë³‘ íŒŒì† ë¦¬ìŠ¤í¬ê°€ í¬ë¯€ë¡œ ë§¤ëŒ€ ë³´ì•ˆ ë° ì§„ì—´ ì•ˆì •ì„± í™•ë³´ê°€ ìµœìš°ì„ ì…ë‹ˆë‹¤.",
                        "ìµœê·¼ ê°€ì„±ë¹„ ìœ„ìŠ¤í‚¤ ì‹œì¥ì˜ ê²½ìŸì´ ì¹˜ì—´í•˜ì—¬, ê°€ê²© ê²½ìŸë ¥ì´ ì†Œí­ë§Œ í•˜ë½í•´ë„ ì¬ê³  íšŒì „ìœ¨ì´ ê¸‰ê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    ],
                    "instant_food": [ # ë¼ë©´/ê°„í¸ì‹
                        f"{target_item}ì€(ëŠ”) ìœ í–‰ ì£¼ê¸°ê°€ ì§§ì€ ì‹í’ˆêµ°ì´ë¯€ë¡œ ì´ˆê¸° í™”ì œì„± ì†Œë©¸ í›„ì˜ ì ì • ì¬ê³  ê´€ë¦¬ê°€ ìˆ˜ìµì„±ì„ ê²°ì •í•©ë‹ˆë‹¤.",
                        "ìê·¹ì ì¸ ë§› ì»¨ì…‰ì¸ ê²½ìš°, ê±´ê°• ì§€í–¥ ì†Œë¹„ìì˜ ë¶€ì •ì  ì—¬ë¡ ì„ ìƒì‡„í•  ì˜ì–‘ ì •ë³´ ë§ˆì¼€íŒ…ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                        "ì›ì¬ë£Œ ìˆ˜ê¸‰ ë¶ˆì•ˆì •ìœ¼ë¡œ ì¸í•œ ìƒì‚° ì°¨ì§ˆ ë¦¬ìŠ¤í¬ë¥¼ ìƒì‹œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤."
                    ],
                    "general": [
                        "ì˜¨ë¼ì¸ ìµœì €ê°€ ë° ëŒ€í˜• ìœ í†µ ì±„ë„ê³¼ì˜ ê°€ê²© ê²©ì°¨ ë°œìƒ ì‹œ í¸ì˜ì  êµ¬ë§¤ ë§¤ë ¥ë„ê°€ ê¸‰ê²©íˆ í•˜ë½í•©ë‹ˆë‹¤.",
                        "SNS ëŒ€ë€ ìƒí’ˆì˜ ê²½ìš°, ë¬¼ëŸ‰ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê³ ê° ë¶ˆë§Œ(í´ë ˆì„) ëŒ€ì‘ ê°€ì´ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
                    ]
                }

                # í‚¤ì›Œë“œ íŒë³„
                cat = "general"
                if any(k in target_item for k in ["ìœ„ìŠ¤í‚¤", "ìˆ ", "í‹°ì³ìŠ¤", "ë‹¤ë‹ˆì—˜", "ì¡°ë‹ˆì›Œì»¤", "í•˜ì´ë³¼"]): cat = "liquor"
                elif any(k in target_item for k in ["ë¼ë©´", "ë©´", "ë³¶ìŒ", "ë„ì‹œë½"]): cat = "instant_food"

                risks = random.sample(risk_db[cat], 2) + random.sample(risk_db["general"], 1)
                
                st.warning(f"1. **ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤í¬**: {risks[0]}")
                st.warning(f"2. **ì‹œì¥ íŠ¸ë Œë“œ ë¦¬ìŠ¤í¬**: {risks[1]}")
                st.warning(f"3. **ìš´ì˜ íš¨ìœ¨ ë¦¬ìŠ¤í¬**: {risks[2]}")

                # ì„¹ì…˜ 3: ë™ì˜ìƒ/ë‰´ìŠ¤
                st.markdown("---")
                st.subheader(f"ğŸ¬ {target_item} ì‹¤ì‹œê°„ ì¶”ì²œ ì½˜í…ì¸ ")
                v_c, n_c = st.columns(2)
                with v_c:
                    for v in get_naver_search('video', target_item):
                        st.info(f"â–¶ [{v['title'].replace('<b>','').replace('</b>','')}]({v['link']})")
                with n_c:
                    for n in get_naver_search('news', target_item):
                        st.info(f"ğŸ“° [{n['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')}]({n['link']})")
