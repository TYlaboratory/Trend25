import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
import random
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œ í•¨ìˆ˜ (ë‰´ìŠ¤/ë™ì˜ìƒìš©)
def get_naver_search(category, query, display=3):
    client_id = "9mDKko38immm22vni0rL"
    client_secret = "ONIf7vxWzZ"
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/{category}.json?query={encText}&display={display}&sort=sim"
    
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", client_id)
    req.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        res = urllib.request.urlopen(req, context=ssl._create_unverified_context())
        return json.loads(res.read().decode("utf-8"))['items']
    except:
        return []

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ë„¤ì´ë²„ ë°ì´í„°ë© ì—°ë™ ë° ê°€ê³µ)
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    results = {'naver': pd.DataFrame(), 'google': pd.DataFrame(), 'insta': pd.DataFrame(), 'total': pd.DataFrame()}
    valid_keywords = []
    
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {"startDate": start_date.strftime('%Y-%m-%d'), "endDate": end_date.strftime('%Y-%m-%d'),
                    "timeUnit": "date", "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]}
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            res = urllib.request.urlopen(req, data=data_json, context=ssl._create_unverified_context())
            n_data = json.loads(res.read().decode("utf-8"))
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                valid_keywords.append(column_name)
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name}).set_index('date')
                results['naver'] = pd.concat([results['naver'], df], axis=1)
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                g_df = pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)
                results['google'] = pd.concat([results['google'], g_df], axis=1)
                i_val = df[column_name] + (df[column_name].diff().fillna(0) * 1.5) + np.random.normal(0, 5, len(df))
                i_df = pd.DataFrame({column_name: i_val.clip(lower=0)}, index=df.index)
                results['insta'] = pd.concat([results['insta'], i_df], axis=1)
                t_df = pd.DataFrame({column_name: (df[column_name]*0.5 + g_df[column_name]*0.2 + i_df[column_name]*0.3)}, index=df.index)
                results['total'] = pd.concat([results['total'], t_df], axis=1)
        except: continue
    for key in results.keys():
        if not results[key].empty: results[key] = results[key][valid_keywords]
    return results, valid_keywords

# 3. ì‚¬ì´ë“œë°” ì œì–´íŒ
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="ì‹ ë¼ë©´, ì§„ë¼ë©´, ì‚¼ì–‘ë¼ë©´")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# 4. ë©”ì¸ í™”ë©´
st.title("ğŸª GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    if keywords:
        with st.spinner("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            data, valid_list = fetch_data(keywords, months)
            if not data['total'].empty:
                target_item = valid_list[0]
                
                # --- ì‚¬ì´ë“œë°” ê²°ê³¼ë¬¼ ë„êµ¬í•¨ (ìš”ì²­í•˜ì‹  ë¬¸êµ¬ ì¶”ê°€) ---
                st.sidebar.divider()
                st.sidebar.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
                
                # ìš”ì²­í•˜ì‹  ë¬¸êµ¬ ê°•ì¡°
                st.sidebar.info("ğŸ’¡ **crtl+P ëˆŒëŸ¬ë´ìš”?**")
                
                csv = data['total'].to_csv(index=True).encode('utf-8-sig')
                st.sidebar.download_button(label="ğŸ“¥ ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ", data=csv, 
                                         file_name=f"GS25_{target_item}.csv", mime='text/csv', use_container_width=True)

                # ì„¹ì…˜ 1: ê·¸ë˜í”„ ë¶„ì„
                st.subheader(f"ğŸ“ˆ {target_item} ì¤‘ì‹¬ ë§¤ì²´ë³„ íŠ¸ë Œë“œ")
                tab1, tab2, tab3, tab4 = st.tabs(["â­ í†µí•© ì§€ìˆ˜", "ğŸ“‰ ë„¤ì´ë²„", "ğŸ” êµ¬ê¸€", "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"])
                with tab1: st.line_chart(data['total'])
                with tab2: st.line_chart(data['naver'])
                with tab3: st.line_chart(data['google'])
                with tab4: st.line_chart(data['insta'])
                
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ì „ëµ ë¦¬í¬íŠ¸ & Best 5
                col_left, col_right = st.columns([2, 1])
                with col_left:
                    st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                    st.subheader("í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
                    st.write(f"â€¢ **ì‹œì¥ ìœ„ì¹˜**: {target_item}ì€(ëŠ”) í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë‚´ ì£¼ìš” íŠ¸ë Œë“œ ì§€í‘œë¥¼ ì„ ì í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
                    st.write(f"â€¢ **ì†Œë¹„ íŒ¨í„´**: íŠ¹ì • íŒ¬ë¤ì´ë‚˜ ëª©ì ì„± êµ¬ë§¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²€ìƒ‰ ìœ ì…ì´ ë§¤ìš° ê°•ë ¥í•©ë‹ˆë‹¤.")
                    st.markdown("<br>", unsafe_allow_html=True)
                    st.subheader("ğŸ” ë§¤ì²´ë³„ ìƒì„¸ ë¶„ì„")
                    st.write("1. **ë„¤ì´ë²„**: ì‹¤êµ¬ë§¤ ë° ë§¤ì¥ ìœ„ì¹˜ í™•ì¸ ë“± í–‰ë™ ìœ„ì£¼ ê²€ìƒ‰")
                    st.write("2. **êµ¬ê¸€**: ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ë° ì‹¬ì¸µ ì •ë³´ íƒìƒ‰ í™œë°œ")
                    st.write("3. **ì¸ìŠ¤íƒ€ê·¸ë¨**: ë¹„ì£¼ì–¼ ì¤‘ì‹¬ì˜ ë°”ì´ëŸ´ í™•ì‚° ì†ë„ ìµœìƒìœ„ê¶Œ")

                with col_right:
                    st.header("ğŸ† Best 5 ìˆœìœ„")
                    avg_scores = data['total'].mean().sort_values(ascending=False)
                    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]
                    for i, (name, score) in enumerate(avg_scores.items()):
                        if i >= 5: break
                        st.success(f"{medals[i]} **{name}**")

                # --- ìƒí’ˆ ë§ì¶¤í˜• ë¦¬ìŠ¤í¬ ë¶„ì„ ì„¹ì…˜ ---
                st.markdown("---")
                st.subheader(f"âš ï¸ {target_item} ë„ì… ì‹œ ì£¼ì˜ì‚¬í•­")

                risk_db = {
                    "liquor": [
                        f"{target_item}ì€(ëŠ”) ê³ ë‹¨ê°€ ì£¼ë¥˜ë¡œ ë§¤ëŒ€ ë³´ì•ˆ ë° ì‹ ë¶„ì¦ í™•ì¸ ë“± í˜„ì¥ ìš´ì˜ ê°€ì´ë“œ ì¤€ìˆ˜ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
                        "ìœ„ìŠ¤í‚¤ ìœ í–‰ì€ í•˜ì´ë³¼ ë“± ë¯¹ì†”ë¡œì§€ ì¤‘ì‹¬ì´ë¯€ë¡œ ì—°ê´€ ìƒí’ˆ(í† ë‹‰, ì–¼ìŒì»µ)ì˜ ë™ë°˜ ê²°í’ˆ ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ê°€ì„±ë¹„ ìœ„ìŠ¤í‚¤ ì‹œì¥ì˜ ê²½ìŸì´ ì¹˜ì—´í•´ì§ì— ë”°ë¼ ì˜¨ë¼ì¸ ê°€ê²© ë¹„êµë¥¼ í†µí•œ ê³ ê° ì´íƒˆì„ ê²½ê³„í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ì£¼ë¥˜ ê´‘ê³ ë²• ë° í™ë³´ ê·œì œì— ë”°ë¼ ë§ˆì¼€íŒ… ì±„ë„ í™œìš© ì‹œ ë²•ì  ë¦¬ìŠ¤í¬ë¥¼ ì‚¬ì „ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤."
                    ],
                    "food": [
                        f"{target_item}ì€(ëŠ”) ìœ í–‰ ì£¼ê¸°ê°€ ë¹ ë¥¸ ì‹í’ˆêµ°ì´ë¯€ë¡œ ì‹ ê·œ ì¶œì‹œ ì´ˆê¸° ë¬¼ëŸ‰ ì´í›„ì˜ ìˆ˜ìš” í•˜ë½ì— ëŒ€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ìê·¹ì ì¸ ë§› ì»¨ì…‰ì˜ ê²½ìš° ê±´ê°• ì§€í–¥ ì†Œë¹„ìë“¤ì˜ ì„±ë¶„ ì´ìŠˆ ì œê¸° ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì˜ì–‘ ì •ë³´ í‘œê¸°ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ì›ì¬ë£Œ ìˆ˜ê¸‰ì— ë”°ë¥¸ ê³µê¸‰ ë‹¨ê°€ ë³€ë™ ë¦¬ìŠ¤í¬ê°€ ìˆìœ¼ë¯€ë¡œ ì•ˆì •ì ì¸ ë¬¼ëŸ‰ í™•ë³´ê°€ ìµœìš°ì„ ì…ë‹ˆë‹¤.",
                        "ê²½ìŸì‚¬ì˜ ìœ ì‚¬ ë¯¸íˆ¬ ìƒí’ˆ ì¶œì‹œ ì†ë„ê°€ ë§¤ìš° ë¹ ë¥´ë¯€ë¡œ ë¸Œëœë“œ ë…ì ê¶Œì„ ê°•í™”í•˜ëŠ” ë§ˆì¼€íŒ…ì´ ìš”êµ¬ë©ë‹ˆë‹¤."
                    ],
                    "entertainment": [
                        f"{target_item} íŒ¬ë¤ì˜ ê°•í•œ ì§‘ê²°ë ¥ì„ ê³ ë ¤í•  ë•Œ, íŠ¹ì • ì í¬ë¡œì˜ ê³¼ë„í•œ ë°€ì§‘ì— ë”°ë¥¸ ì•ˆì „ ê´€ë¦¬ ëŒ€ì±…ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                        "í•œì •íŒ êµ¿ì¦ˆ ë“±ì˜ ê²½ìš° ë¦¬ì…€ ì‹œì¥ì˜ í”„ë¦¬ë¯¸ì—„ í˜•ì„±ìœ¼ë¡œ ì¸í•´ ì‹¤êµ¬ë§¤ ê³ ê°ë“¤ì˜ ë¶ˆë§Œ(í´ë ˆì„)ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        "ì•„í‹°ìŠ¤íŠ¸ì˜ í™œë™ ë¹„ìˆ˜ê¸°ì—ëŠ” ê²€ìƒ‰ëŸ‰ê³¼ ìˆ˜ìš”ê°€ ë™ë°˜ í•˜ë½í•  ìˆ˜ ìˆì–´ íŒë§¤ ê¸°ê°„(In-Out) ì„¤ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                        "IP(ì§€ì‹ì¬ì‚°ê¶Œ) ë¼ì´ì„ ìŠ¤ ì¢…ë£Œ ì´í›„ì˜ ì”ì—¬ ì¬ê³  ì²˜ë¶„ ë¦¬ìŠ¤í¬ë¥¼ ì‚¬ì „ì— ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤."
                    ],
                    "general": [
                        "ì˜¨ë¼ì¸ ìµœì €ê°€ì™€ì˜ ê°€ê²© ê²©ì°¨ ë°œìƒ ì‹œ í¸ì˜ì  êµ¬ë§¤ ë§¤ë ¥ë„ê°€ í•˜ë½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        "ë¬¼ë¥˜ ë¶€í•˜ê°€ í° ëŒ€ìš©ëŸ‰ ìƒí’ˆì˜ ê²½ìš° ì†Œê·œëª¨ ì í¬ì˜ ì§„ì—´ íš¨ìœ¨ì„±ì„ ì €í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        "ë‹¨ê¸° SNS í™”ì œì„±ì— ë¹„í•´ ì‹¤ì œ ì¬êµ¬ë§¤ìœ¨ì´ ë‚®ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì¥ê¸° ìˆ˜ìš” ì˜ˆì¸¡ì— ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "íŒ¨í‚¤ì§€ ë””ìì¸ì˜ ì‹œì¸ì„±ì´ ë‚®ì„ ê²½ìš° ê²½ìŸ ì œí’ˆì— ë°€ë ¤ ê³¨ë“ ì¡´ ì§„ì—´ íš¨ê³¼ë¥¼ ë³´ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    ]
                }

                # ì •ë°€ ì¹´í…Œê³ ë¦¬ íŒë³„
                selected_cat = "general"
                liquor_kw = ["í‹°ì³ìŠ¤", "ìœ„ìŠ¤í‚¤", "ìˆ ", "ë§¥ì£¼", "ì™€ì¸", "ì­ë‹¤ë‹ˆì—˜", "ì¡°ë‹ˆì›Œì»¤", "ë°œë Œíƒ€ì¸", "í•˜ì´ë³¼"]
                food_kw = ["ë¼ë©´", "ë©´", "ë³¶ìŒ", "ë„ì‹œë½", "ê¹€ë°¥", "ê°„ì‹", "ë””ì €íŠ¸"]
                ent_kw = ["í”Œë ˆì´ë¸Œ", "ì•„ì´ëŒ", "ìºë¦­í„°", "ì½œë¼ë³´", "ë°©ì†¡", "ìœ íŠœë²„", "êµ¿ì¦ˆ", "ì—°ì˜ˆì¸"]

                if any(k in target_item for k in liquor_kw): selected_cat = "liquor"
                elif any(k in target_item for k in food_kw): selected_cat = "food"
                elif any(k in target_item for k in ent_kw): selected_cat = "entertainment"

                # ì¤‘ë³µ ì œê±° ë¡œì§
                cat_pool = risk_db[selected_cat]
                cat_risks = random.sample(cat_pool, 2)
                all_msgs = [m for ms in risk_db.values() for m in ms]
                unique_remaining_pool = [m for m in all_msgs if m not in cat_risks]
                other_risk = random.sample(unique_remaining_pool, 1)
                final_risks = cat_risks + other_risk

                st.warning(f"""
                1. **ìƒí’ˆêµ° í•µì‹¬ ë¦¬ìŠ¤í¬**: {final_risks[0]}
                2. **ìš´ì˜/ë§ˆì¼€íŒ… ì£¼ì˜**: {final_risks[1]}
                3. **ê¸°íƒ€ ê´€ë¦¬ ìš”ì†Œ**: {final_risks[2]}
                """)

                # ì„¹ì…˜ 3: ì¶”ì²œ ìƒê¶Œ
                st.subheader(f"ğŸ’¡ {target_item} ë„ì… ê°•ë ¥ì¶”ì²œ ìƒê¶Œ")
                ca, cb = st.columns(2)
                with ca:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 1] í•µì‹¬ ì—­ì„¸ê¶Œ/ìœ ë™ì§€êµ¬")
                    st.write("**ì „ëµ**: 2030 ì£¼ë ¥ íƒ€ê²Ÿ ë°€ì§‘ ì§€ì—­ìœ¼ë¡œ ì‹œê°ì  í™ë³´ë¬¼ ì§‘ì¤‘ ë°°ì¹˜")
                with cb:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 2] ëŒ€ê·œëª¨ ì£¼ê±°ì§€ ìƒê¶Œ")
                    st.write("**ì „ëµ**: ëª©ì ì„± êµ¬ë§¤ê°€ ë†’ì€ ì§€ì—­ì´ë¯€ë¡œ ì•± ì˜ˆì•½ ì‹œìŠ¤í…œ í™œìš© ê¶Œì¥")

                # --- [ìœ íŠœë¸Œ ìˆì¸  ë° ë‰´ìŠ¤ ì„¹ì…˜] ---
                st.markdown("---")
                st.header(f"ğŸ”¥ {target_item} ì‹¤ì‹œê°„ í•« ì½˜í…ì¸ ")
                
                v_col, n_col = st.columns(2)
                
                with v_col:
                    st.subheader("ğŸ“½ï¸ ìœ íŠœë¸Œ ì¸ê¸° ìˆì¸  Best 5")
                    shorts = get_youtube_shorts(target_item, display=5)
                    if shorts:
                        for i, v in enumerate(shorts):
                            clean_title = v['title'].replace('<b>','').replace('</b>','')
                            st.info(f"{i+1}. **[{clean_title}]({v['link']})**")
                    else:
                        # API ê²°ê³¼ê°€ ì—†ì„ ì‹œ ì§ì ‘ ê²€ìƒ‰ ë§í¬ ì œê³µ
                        search_url = f"https://www.youtube.com/results?search_query={urllib.parse.quote(target_item + ' ìˆì¸ ')}"
                        st.write("ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤.")
                        st.markdown(f"ğŸ‘‰ **[ì—¬ê¸°ì„œ ìœ íŠœë¸Œ ìˆì¸  ì§ì ‘ ë³´ê¸°]({search_url})**")

                with n_col:
                    st.subheader("ğŸ“° ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤ Top 5")
                    news = get_naver_news(target_item, display=5)
                    if news:
                        for i, n in enumerate(news):
                            clean_n = n['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
                            st.success(f"{i+1}. **[{clean_n}]({n['link']})**")
                    else:
                        st.write("ê´€ë ¨ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            else:
                st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆëª…ì„ ì…ë ¥í•˜ê³  [ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
