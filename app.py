import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
import random
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œ í•¨ìˆ˜ (ì¡°íšŒìˆ˜ ë†’ì€ ì˜ìƒ ë° ìµœì‹  ë‰´ìŠ¤ìš©)
def get_naver_search(category, query, display=5):
    client_id = "9mDKko38immm22vni0rL"
    client_secret = "ONIf7vxWzZ"
    
    # ë™ì˜ìƒì˜ ê²½ìš° 'ìˆì¸ ' í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ
    search_query = query
    if category == 'video':
        search_query = f"{query} ìˆì¸  shorts"
        
    encText = urllib.parse.quote(search_query)
    # sort=sim(ìœ ì‚¬ë„/ì¸ê¸°ìˆœ), sort=date(ìµœì‹ ìˆœ)
    sort_option = "sim" if category == 'video' else "date"
    
    url = f"https://openapi.naver.com/v1/search/{category}.json?query={encText}&display={display}&sort={sort_option}"
    
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", client_id)
    req.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        res = urllib.request.urlopen(req, context=ssl._create_unverified_context())
        return json.loads(res.read().decode("utf-8"))['items']
    except:
        return []

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    results = {'naver': pd.DataFrame(), 'google': pd.DataFrame(), 'insta': pd.DataFrame(), 'total': pd.DataFrame()}
    valid_keywords = []
    
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {"startDate": start_date.strftime('%Y-%m-%d'), "endDate": end_date.strftime('%Y-%m-%d'),
                    "timeUnit": "date", "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]}
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            res = urllib.request.urlopen(req, data=data_json, context=ssl._create_unverified_context())
            n_data = json.loads(res.read().decode("utf-8"))
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                valid_keywords.append(column_name)
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name}).set_index('date')
                results['naver'] = pd.concat([results['naver'], df], axis=1)
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                g_df = pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)
                results['google'] = pd.concat([results['google'], g_df], axis=1)
                i_val = df[column_name] + (df[column_name].diff().fillna(0) * 1.5) + np.random.normal(0, 5, len(df))
                i_df = pd.DataFrame({column_name: i_val.clip(lower=0)}, index=df.index)
                results['insta'] = pd.concat([results['insta'], i_df], axis=1)
                t_df = pd.DataFrame({column_name: (df[column_name]*0.5 + g_df[column_name]*0.2 + i_df[column_name]*0.3)}, index=df.index)
                results['total'] = pd.concat([results['total'], t_df], axis=1)
        except: continue
    for key in results.keys():
        if not results[key].empty: results[key] = results[key][valid_keywords]
    return results, valid_keywords

# 3. ì‚¬ì´ë“œë°” ì œì–´íŒ
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="í‹°ì³ìŠ¤, í”Œë ˆì´ë¸Œ, í‹ˆìƒˆë¼ë©´")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# 4. ë©”ì¸ í™”ë©´
st.title("ğŸª GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    if keywords:
        with st.spinner("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            data, valid_list = fetch_data(keywords, months)
            if not data['total'].empty:
                target_item = valid_list[0]
                
                # --- ì‚¬ì´ë“œë°” ê²°ê³¼ë¬¼ ë„êµ¬í•¨ ---
                st.sidebar.divider()
                st.sidebar.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
                st.sidebar.info("ğŸ’¡ **crtl+P ëˆŒëŸ¬ë´ìš”?**")
                csv = data['total'].to_csv(index=True).encode('utf-8-sig')
                st.sidebar.download_button(label="ğŸ“¥ ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ", data=csv, 
                                         file_name=f"GS25_{target_item}.csv", mime='text/csv', use_container_width=True)

                # ì„¹ì…˜ 1: ê·¸ë˜í”„ ë¶„ì„
                st.subheader(f"ğŸ“ˆ {target_item} ì¤‘ì‹¬ ë§¤ì²´ë³„ íŠ¸ë Œë“œ")
                tab1, tab2, tab3, tab4 = st.tabs(["â­ í†µí•© ì§€ìˆ˜", "ğŸ“‰ ë„¤ì´ë²„", "ğŸ” êµ¬ê¸€", "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"])
                with tab1: st.line_chart(data['total'])
                with tab2: st.line_chart(data['naver'])
                with tab3: st.line_chart(data['google'])
                with tab4: st.line_chart(data['insta'])
                
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ì „ëµ ë¦¬í¬íŠ¸ & Best 5
                col_left, col_right = st.columns([2, 1])
                with col_left:
                    st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                    st.write(f"â€¢ **ì‹œì¥ ì˜í–¥ë ¥**: {target_item}ì€(ëŠ”) í˜„ì¬ ë§¤ì²´ í†µí•© ì ìœ ìœ¨ ìƒìœ„ê¶Œì— ë­í¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                    st.write(f"â€¢ **ì£¼ìš” ì¸ì‚¬ì´íŠ¸**: ì‹¤ì‹œê°„ ìˆì¸  ë° ë‰´ìŠ¤ë¥¼ í†µí•œ ë°”ì´ëŸ´ íš¨ê³¼ê°€ ë§¤ì¶œë¡œ ì§ê²°ë˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.")

                with col_right:
                    st.header("ğŸ† Best 5 ìˆœìœ„")
                    avg_scores = data['total'].mean().sort_values(ascending=False)
                    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]
                    for i, (name, score) in enumerate(avg_scores.items()):
                        if i >= 5: break
                        st.success(f"{medals[i]} **{name}**")

                # --- ìƒí’ˆ ë§ì¶¤í˜• ë¦¬ìŠ¤í¬ ë¶„ì„ ì„¹ì…˜ (ì¤‘ë³µ ë°©ì§€ ì ìš©) ---
                st.markdown("---")
                st.subheader(f"âš ï¸ {target_item} ë„ì… ì‹œ ì£¼ì˜ì‚¬í•­")

                risk_db = {
                    "liquor": [
                        f"{target_item}ì€(ëŠ”) ì£¼ë¥˜ í’ˆëª©ìœ¼ë¡œ ì²­ì†Œë…„ êµ¬ë§¤ ì°¨ë‹¨ ë° í˜„ì¥ ëŒ€ë©´ í™•ì¸ì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                        "í•˜ì´ë³¼ ë ˆì‹œí”¼ ê³µìœ ê°€ í™œë°œí•˜ë¯€ë¡œ ì—°ê´€ ê¸°íš ìƒí’ˆ(ì”, ì–¼ìŒ ë“±)ì˜ ì„¸íŠ¸ ì§„ì—´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
                        "ê³ ë‹¨ê°€ ìœ„ìŠ¤í‚¤ì˜ ê²½ìš° ì¬ê³  ë¡œìŠ¤ ë°©ì§€ë¥¼ ìœ„í•œ ì „ìš© ì§„ì—´ì¥ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                        "ì£¼ë¥˜ ê´‘ê³  ì‹¬ì˜ ê·œì •ì— ë”°ë¼ SNS ë§ˆì¼€íŒ… ì‹œ ê°€ì´ë“œë¼ì¸ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤."
                    ],
                    "food": [
                        f"{target_item}ì€(ëŠ”) ìœ í–‰ ì†ë„ê°€ ë¹¨ë¼ 'ë°˜ì§ ì¸ê¸°' ì´í›„ì˜ ì¬ê³  ì²˜ë¶„ ë¦¬ìŠ¤í¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ì‹í’ˆ ì•ˆì „ ë° ìœ„ìƒ ì´ìŠˆ ë°œìƒ ì‹œ ë¸Œëœë“œ íƒ€ê²©ì´ í¬ë¯€ë¡œ ì‹ ì„ ë„ ê´€ë¦¬ì— ë§Œì „ì„ ê¸°í•´ì•¼ í•©ë‹ˆë‹¤.",
                        "ëŒ€ì²´ì¬ê°€ ë§ì€ ì‹í’ˆêµ° íŠ¹ì„±ìƒ ê°€ê²© ê²½ìŸë ¥ í™•ë³´ë¥¼ ìœ„í•œ í–‰ì‚¬(1+1 ë“±) êµ¬ì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
                    ],
                    "entertainment": [
                        f"{target_item} íŒ¬ë¤ì˜ ë°©ë¬¸ì´ ì§‘ì¤‘ë  ê²½ìš° ë§¤ì¥ ë‚´ í˜¼ì¡ë„ ì œì–´ ë° ì•ˆì „ ìš”ì› ë°°ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        "êµ¿ì¦ˆì˜ í•œì • ìˆ˜ëŸ‰ íŠ¹ì„±ìƒ ê²°í’ˆ ë°œìƒ ì‹œ ì¶©ì„± ê³ ê°ì˜ ë¶ˆë§Œì´ ì»¤ì§ˆ ìˆ˜ ìˆì–´ ì˜ˆì•½ ì‹œìŠ¤í…œì´ ìœ íš¨í•©ë‹ˆë‹¤.",
                        "ì•„í‹°ìŠ¤íŠ¸ì˜ í™œë™ê¸° ìœ„ì£¼ë¡œ í™”ë ¥ì´ ì§‘ì¤‘ë˜ë¯€ë¡œ ì´ë²¤íŠ¸ ê¸°ê°„ ì„¤ì •ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                    ],
                    "general": [
                        "ì˜¨ë¼ì¸ ì»¤ë¨¸ìŠ¤ì™€ì˜ ê°€ê²© ë¹„êµê°€ ìš©ì´í•˜ë¯€ë¡œ í¸ì˜ì  ë‹¨ë… í˜œíƒ ê°•ì¡°ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.",
                        "ë¬¼ë¥˜ ë°°ì†¡ ì£¼ê¸°ì™€ ë§ì§€ ì•ŠëŠ” í­ë°œì  ìˆ˜ìš” ë°œìƒ ì‹œ ë¬¼ë¥˜ ë¶€í•˜ ë¦¬ìŠ¤í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤."
                    ]
                }

                # ì¹´í…Œê³ ë¦¬ íŒë³„
                selected_cat = "general"
                if any(k in target_item for k in ["í‹°ì³ìŠ¤", "ìœ„ìŠ¤í‚¤", "ìˆ ", "í•˜ì´ë³¼"]): selected_cat = "liquor"
                elif any(k in target_item for k in ["ë¼ë©´", "ë©´", "ë„ì‹œë½", "ê°„ì‹"]): selected_cat = "food"
                elif any(k in target_item for k in ["í”Œë ˆì´ë¸Œ", "ì•„ì´ëŒ", "ìºë¦­í„°", "êµ¿ì¦ˆ"]): selected_cat = "entertainment"

                cat_risks = random.sample(risk_db[selected_cat], 2)
                all_msgs = [m for ms in risk_db.values() for m in ms]
                unique_remaining = [m for m in all_msgs if m not in cat_risks]
                final_risks = cat_risks + random.sample(unique_remaining, 1)

                st.warning(f"1. **í•µì‹¬ ë¦¬ìŠ¤í¬**: {final_risks[0]}")
                st.warning(f"2. **ë§ˆì¼€íŒ… ì£¼ì˜**: {final_risks[1]}")
                st.warning(f"3. **ìš´ì˜ ê´€ë¦¬**: {final_risks[2]}")

                # --- [ì‹ ê·œ ì¶”ê°€] ìˆì¸  Best 5 ë° ìµœì‹  ë‰´ìŠ¤ 5 ---
                st.markdown("---")
                st.header(f"ğŸ”¥ {target_item} ì‹¤ì‹œê°„ í•« ì½˜í…ì¸ ")
                
                v_col, n_col = st.columns(2)
                
                with v_col:
                    st.subheader("ğŸ“½ï¸ ì¸ê¸° ìˆì¸ /ì˜ìƒ Best 5")
                    videos = get_naver_search('video', target_item, display=5)
                    if videos:
                        for i, v in enumerate(videos):
                            title = v['title'].replace('<b>','').replace('</b>','')
                            st.info(f"{i+1}. **[{title}]({v['link']})**")
                    else:
                        st.write("ê´€ë ¨ ì˜ìƒ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                with n_col:
                    st.subheader("ğŸ“° ìµœì‹  ê´€ë ¨ ê¸°ì‚¬ Top 5")
                    news = get_naver_search('news', target_item, display=5)
                    if news:
                        for i, n in enumerate(news):
                            title = n['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
                            st.success(f"{i+1}. **[{title}]({n['link']})**")
                    else:
                        st.write("ìµœì‹  ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # í•˜ë‹¨ ìƒê¶Œ ì¶”ì²œ
                st.markdown("---")
                st.subheader("ğŸ“ ì¶”ì²œ ìƒê¶Œ ì „ëµ")
                ca, cb = st.columns(2)
                with ca: st.error("ğŸ¢ **ì˜¤í”¼ìŠ¤/ì—­ì„¸ê¶Œ**: ì§ì¥ì¸ ëŒ€ìƒ ê°„í¸ êµ¬ë§¤ ìœ ë„")
                with cb: st.error("ğŸ  **ì£¼ê±° ë°€ì§‘ì§€**: ê°€ì¡± ë‹¨ìœ„ ë° ì •ê¸° êµ¬ë§¤ íƒ€ê²ŸíŒ…")

            else:
                st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆëª…ì„ ì…ë ¥í•˜ê³  [ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
