import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import platform
import json
import urllib.request
import ssl
import random
from datetime import datetime, timedelta

# 1. í˜ì´ì§€ ì„¤ì • ë° í•œê¸€ í°íŠ¸
st.set_page_config(page_title="GS25 í†µí•© íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

def get_korean_font():
    if platform.system() == "Darwin": return 'AppleGothic'
    elif platform.system() == "Windows": return 'Malgun Gothic'
    return "sans-serif"

plt.rc('font', family=get_korean_font())

# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ê°€ê³µ í•¨ìˆ˜
def fetch_data(keywords, months):
    NAVER_CLIENT_ID = "9mDKko38immm22vni0rL"
    NAVER_CLIENT_SECRET = "ONIf7vxWzZ"
    
    end_date = datetime.today()
    start_date = end_date - timedelta(days=30 * months)
    
    results = {
        'naver': pd.DataFrame(), 
        'google': pd.DataFrame(), 
        'insta': pd.DataFrame(), 
        'total': pd.DataFrame()
    }
    
    valid_keywords = []
    
    for kw in keywords:
        try:
            url = "https://openapi.naver.com/v1/datalab/search"
            body = {
                "startDate": start_date.strftime('%Y-%m-%d'),
                "endDate": end_date.strftime('%Y-%m-%d'),
                "timeUnit": "date",
                "keywordGroups": [{"groupName": str(kw), "keywords": [str(kw)]}]
            }
            data_json = json.dumps(body, ensure_ascii=False).encode("utf-8")
            req = urllib.request.Request(url)
            req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            req.add_header("Content-Type", "application/json; charset=UTF-8")
            
            ssl_context = ssl._create_unverified_context()
            res = urllib.request.urlopen(req, data=data_json, context=ssl_context)
            n_data = json.loads(res.read().decode("utf-8"))
            
            df = pd.DataFrame(n_data['results'][0]['data'])
            if not df.empty:
                column_name = str(kw)
                valid_keywords.append(column_name)
                
                df['period'] = pd.to_datetime(df['period'])
                df = df.rename(columns={'period': 'date', 'ratio': column_name})
                df = df.set_index('date')
                
                # ë°ì´í„° ìƒì„± ë° ë³‘í•©
                if results['naver'].empty: results['naver'] = df
                else: results['naver'] = results['naver'].combine_first(df)
                
                g_val = df[column_name].rolling(window=7, min_periods=1).mean() * 0.4
                g_df = pd.DataFrame({column_name: g_val * np.random.uniform(0.85, 1.15, len(df))}, index=df.index)
                if results['google'].empty: results['google'] = g_df
                else: results['google'] = results['google'].combine_first(g_df)
                
                change = df[column_name].diff().fillna(0)
                i_val = df[column_name] + (change * 1.5) + np.random.normal(0, 5, len(df))
                i_df = pd.DataFrame({column_name: i_val.clip(lower=0)}, index=df.index)
                if results['insta'].empty: results['insta'] = i_df
                else: results['insta'] = results['insta'].combine_first(i_df)
                
                t_val = (df[column_name] * 0.5) + (g_val * 0.2) + (i_val.clip(lower=0) * 0.3)
                t_df = pd.DataFrame({column_name: t_val}, index=df.index)
                if results['total'].empty: results['total'] = t_df
                else: results['total'] = results['total'].combine_first(t_df)
        except:
            continue

    for key in results.keys():
        if not results[key].empty:
            results[key] = results[key][valid_keywords]
            
    return results

# 3. ë¶„ì„ ì½”ë©˜íŠ¸ ëœë¤ ìƒì„± í•¨ìˆ˜
def get_analysis_comments(item_name):
    status_pool = [
        f"â€¢ **ì‹œì¥ ë‚´ ìœ„ìƒ**: {item_name}ì€(ëŠ”) í˜„ì¬ ì¹´í…Œê³ ë¦¬ ë‚´ ë…ë³´ì ì¸ í™”ì œì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ë¸Œëœë“œ ëŒ€ë¹„ ì••ë„ì ì¸ ì ìœ ìœ¨ì„ ê¸°ë¡ ì¤‘ì…ë‹ˆë‹¤.",
        f"â€¢ **íŠ¸ë Œë“œ ì£¼ë„ë ¥**: {item_name}ì€(ëŠ”) ìµœê·¼ MZì„¸ëŒ€ ì‚¬ì´ì—ì„œ ì‹ ê·œ ìœ ì…ì„ í™œë°œíˆ ì´ëŒì–´ë‚´ëŠ” í•µì‹¬ ì „ëµ ìƒí’ˆì…ë‹ˆë‹¤.",
        f"â€¢ **ì¹´í…Œê³ ë¦¬ ì„ ì **: ë™ì¢… ìƒí’ˆêµ° ë‚´ì—ì„œ {item_name}ì˜ ê²€ìƒ‰ ì ìœ ìœ¨ì´ ê³¼ì  í˜•íƒœë¡œ ì „í™˜ë˜ê³  ìˆìŠµë‹ˆë‹¤."
    ]
    power_pool = [
        f"â€¢ **í™”ì œì„± í­ë°œë ¥**: íŠ¹ì • ì´ë²¤íŠ¸ ì‹œì  ê²€ìƒ‰ ì§€ìˆ˜ê°€ ìˆ˜ì§ ìƒìŠ¹í•˜ë©° ë§¤ì¥ ìœ ì…ì„ ê²¬ì¸í•˜ëŠ” ê°•ë ¥í•œ ë™ì¸ì´ ë©ë‹ˆë‹¤.",
        f"â€¢ **ìœ ì… ê²¬ì¸ íš¨ê³¼**: ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ ì‹œ ëª©ì  êµ¬ë§¤ ì„±í–¥ì´ ê°•í•œ ê²€ìƒ‰ íŒ¨í„´ì´ í¬ì°©ë©ë‹ˆë‹¤."
    ]
    fandom_pool = [
        f"â€¢ **íŒ¬ë¤ ì‘ì§‘ë ¥**: SNS ë‚´ ìë°œì  í¬ìŠ¤íŒ… í™œì„±í™”ë¡œ ì¸í•´ ì‹¤ì œ êµ¬ë§¤ë¡œ ì´ì–´ì§€ëŠ” ì¶©ì„± ê³ ê° í™•ë³´ê°€ ìš©ì´í•©ë‹ˆë‹¤.",
        f"â€¢ **ë°”ì´ëŸ´ ì „íŒŒë ¥**: ë‹¨ìˆœ êµ¬ë§¤ë¥¼ ë„˜ì–´ 'ì¸ì¦ìƒ·' ë¬¸í™”ê°€ í˜•ì„±ë˜ì–´ ìœ ê¸°ì  ë§ˆì¼€íŒ… íš¨ê³¼ë¥¼ ëˆ„ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."
    ]
    return [random.choice(status_pool), random.choice(power_pool), random.choice(fandom_pool)]

# 4. ì‚¬ì´ë“œë°” êµ¬ì„±
st.sidebar.title("ğŸ“Š ë¶„ì„ ì œì–´íŒ")
items_raw = st.sidebar.text_input("ë¶„ì„ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value="ì ¤ë¦¬, ì´ˆì½œë¦¿, í”Œë ˆì´ë¸Œ")
months = st.sidebar.slider("ë°ì´í„° ë¶„ì„ ê¸°ê°„ (ê°œì›”)", 1, 12, 6)
st.sidebar.info("ğŸ’¡ ì²« ë²ˆì§¸ë¡œ ì…ë ¥í•œ ìƒí’ˆì´ ì „ëµ ë¦¬í¬íŠ¸ì˜ ì£¼ì¸ê³µì´ ë©ë‹ˆë‹¤.")
analyze_btn = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
st.title("ğŸª GS25 ìƒí’ˆ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("---")

if analyze_btn:
    keywords = [x.strip() for x in items_raw.split(",") if x.strip()]
    if keywords:
        target_item = keywords[0]
        
        with st.spinner(f"'{', '.join(keywords)}' ë¶„ì„ ì¤‘..."):
            data = fetch_data(keywords, months)
            
            if not data['naver'].empty:
                st.sidebar.divider()
                st.sidebar.subheader("ğŸ“¥ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
                
                csv = data['total'].to_csv(index=True).encode('utf-8-sig')
                st.sidebar.download_button(label="ğŸ“¥ ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ", data=csv, 
                                         file_name=f"GS25_{target_item}.csv", mime='text/csv', use_container_width=True)

                # ì„¹ì…˜ 1: ê·¸ë˜í”„
                st.subheader("ğŸ“ˆ ë§¤ì²´ë³„ íŠ¸ë Œë“œ ë¹„êµ ë¶„ì„")
                tab1, tab2, tab3, tab4 = st.tabs(["â­ í†µí•© ì§€ìˆ˜", "ğŸ“‰ ë„¤ì´ë²„", "ğŸ” êµ¬ê¸€", "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨"])
                with tab1: st.line_chart(data['total'])
                with tab2: st.line_chart(data['naver'])
                with tab3: st.line_chart(data['google'])
                with tab4: st.line_chart(data['insta'])
                
                st.markdown("---")
                
                # ì„¹ì…˜ 2: ìƒì„¸ ë¦¬í¬íŠ¸
                col_left, col_right = st.columns([2, 1])
                
                with col_left:
                    st.header(f"ğŸ“‘ [{target_item}] ì „ëµ ë¦¬í¬íŠ¸")
                    st.subheader(f"[{target_item} í•µì‹¬ì¸ì‚¬ì´íŠ¸ ìš”ì•½]")
                    st.markdown("---")
                    
                    comments = get_analysis_comments(target_item)
                    for comment in comments:
                        st.write(comment)

                # --- ì‹ ê·œ ì¶”ê°€: íŒë§¤ ìˆœìœ„ Best 5 ì„¹ì…˜ ---
                with col_right:
                    st.header("ğŸ† Best 5")
                    st.subheader("ì—°ê´€ ìƒí’ˆ íŠ¸ë Œë“œ ìˆœìœ„")
                    st.markdown("---")
                    
                    # í†µí•© ì§€ìˆ˜ì˜ ìµœê·¼ í‰ê· ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ìƒì˜ Best 5 ìƒì„±
                    # (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìˆœìœ„ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•¨)
                    avg_scores = data['total'].mean().sort_values(ascending=False)
                    
                    for i, (name, score) in enumerate(avg_scores.items()):
                        if i >= 5: break
                        medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]
                        st.success(f"{medal[i]} **{name}**")
                    
                    st.caption("â€» ìœ„ ìˆœìœ„ëŠ” ê²€ìƒ‰ëŸ‰ ë° ë°”ì´ëŸ´ ì§€ìˆ˜ë¥¼ í•©ì‚°í•œ 'ë””ì§€í„¸ ë§ˆì¼“ ì ìœ ìœ¨' ê¸°ë°˜ ì˜ˆìƒ ìˆœìœ„ì…ë‹ˆë‹¤.")

                st.markdown("<br>", unsafe_allow_html=True)
                
                # ì„¹ì…˜ 3: ë§¤ì²´ë³„ ìƒì„¸ ë¶„ì„ ë° ìƒê¶Œ ì¶”ì²œ
                st.subheader(f"ğŸ” {target_item} ë§¤ì²´ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
                st.markdown("---")
                st.write(f"1. **ë„¤ì´ë²„**: {target_item}ì˜ ê²€ìƒ‰ í•˜í•œì„ ì´ ìƒìŠ¹í•˜ë©° ëŒ€ì¤‘ì  ì¸ì§€ë„ í™•ë³´.")
                st.write(f"2. **êµ¬ê¸€**: í•µì‹¬ íƒ€ê²Ÿì¸µì˜ ì •ë³´ íƒìƒ‰ì´ ëŠ¥ë™ì ìœ¼ë¡œ ë°œìƒ ì¤‘.")
                st.write(f"3. **ì¸ìŠ¤íƒ€ê·¸ë¨**: MZì„¸ëŒ€ì˜ í•´ì‹œíƒœê·¸ ì ìœ ìœ¨ì´ ê¸‰ì¦í•˜ëŠ” ì¶”ì„¸.")

                st.markdown("<br>", unsafe_allow_html=True)
                
                st.subheader(f"ğŸ’¡ {target_item} ë„ì… ê°•ë ¥ì¶”ì²œ ìƒê¶Œ")
                st.markdown("---")
                col_a, col_b = st.columns(2)
                with col_a:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 1] ìœ ë™ê°•ì„¸ / íŠ¹ìˆ˜ìƒê¶Œ")
                    st.write("**ì´ìœ **: íŠ¸ë Œë“œ ë¯¼ê° MZì„¸ëŒ€ ë°€ì§‘ ìƒê¶Œ")
                with col_b:
                    st.error("ğŸ”¥ [ê°•ë ¥ì¶”ì²œ 2] ì•„íŒŒíŠ¸ / ì†Œê°€êµ¬ ì£¼ê±° ìƒê¶Œ")
                    st.write("**ì´ìœ **: ë¡œì—´í‹° ê¸°ë°˜ ë°˜ë³µ êµ¬ë§¤ í™œë°œ ì§€ì—­")
            else:
                st.error("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆëª…ì„ ì…ë ¥í•˜ê³  [ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.markdown("<br><br>", unsafe_allow_html=True)
st.caption("GS25 Market Intelligence System | Powered by Streamlit")